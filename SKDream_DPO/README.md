# SKDream Multi-view and 3D Generation Pipeline

## Inference
We provide a step-by-step inference pipeline which saves intermediate results for each step. The full pipeline uses multiple model checkpoints include [skdream](https://huggingface.co/yoxu515/skdream), [mvdream](https://huggingface.co/lzq49/mvdream-sd21-diffusers), [instantmesh (mesh_large)](https://huggingface.co/TencentARC/InstantMesh), [sd1.5](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5), [controlnet-canny](https://huggingface.co/lllyasviel/sd-controlnet-canny), [controlnet-tile](https://huggingface.co/lllyasviel/control_v11f1e_sd15_tile), [cosa](https://huggingface.co/yoxu515/skdream), [dinov2 (vitl14_reg4_pretrain)](https://github.com/facebookresearch/dinov2). Download and put them into ckpt folder.

```
cd skdream_model
bash infer_skdream.sh
```
The pipeline consits of:
- ```infer_mv.py```: Run multi-view inference. Require mvdream and skdream checkpoints in ckpt.

- ```infer_rec.py```: Reconstruct 3D textured meshes from multi-view images. Require InstantMesh checkpoints in ckpt/InstantMesh_ckpt.

- ```infer_tile.py```: Upscaled images are generated by ControlNet tiling. Require SD1.5, ControlNet-Edge and ControlNet-Tile checkpoints in ckpt.

- ```infer_refine.py```: Refined textures are generated by UV space optimization.





### Evaluation
```eval_align.py```: Calculate object and skeleton alignment (SKA) score. Require dinov2 code in current dir, cosa.pth and dinov2_vitl14_reg4_pretrain.pth checkpoints in ckpt/cosa.

## Training
Prepare the training data following skdream_data part.

```train_skdream.sh```: Train the multi-view model on rendered data pairs.